{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-0001",
   "metadata": {},
   "source": [
    "# Phase 3 — Reranker Training: LoRA + Knowledge Distillation\n",
    "\n",
    "This notebook trains a two-stage reranker pipeline:\n",
    "1. **Teacher**: CodeBERT fine-tuned with LoRA on assert-review pairs\n",
    "2. **Student**: CodeT5-small distilled from teacher logits (2× smaller, 5× faster)\n",
    "\n",
    "Output checkpoint saved to `ml/models/reranker/`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-0002",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0003",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers peft datasets accelerate torch scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Resolve project root\n",
    "PROJECT_ROOT = Path(\"../..\").resolve()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "DATA_PATH = PROJECT_ROOT / \"ml\" / \"data\" / \"reranker_pairs.jsonl\"\n",
    "CHECKPOINT_DIR = PROJECT_ROOT / \"ml\" / \"models\" / \"reranker\"\n",
    "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Data path: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-0005",
   "metadata": {},
   "source": [
    "## 2. Data — Load JSONL and Build RerankerDataset\n",
    "\n",
    "Expected JSONL format (one record per line):\n",
    "```json\n",
    "{\"text\": \"<file>src/auth/jwt.py ...diff...\", \"label\": 1}\n",
    "```\n",
    "`label=1` means the diff is important for review; `label=0` means it can be deprioritized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(path: Path) -> list[dict]:\n",
    "    records = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                records.append(json.loads(line))\n",
    "    return records\n",
    "\n",
    "\n",
    "class RerankerDataset(Dataset):\n",
    "    \"\"\"Tokenised dataset for binary importance classification.\"\"\"\n",
    "\n",
    "    def __init__(self, records: list[dict], tokenizer, max_length: int = 512):\n",
    "        self.records = records\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        rec = self.records[idx]\n",
    "        enc = self.tokenizer(\n",
    "            rec[\"text\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(rec[\"label\"], dtype=torch.float),\n",
    "        }\n",
    "\n",
    "\n",
    "# Generate synthetic data if real data is missing (for notebook demo)\n",
    "if not DATA_PATH.exists():\n",
    "    print(f\"WARNING: {DATA_PATH} not found. Generating synthetic demo data.\")\n",
    "    DATA_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    samples = [\n",
    "        {\"text\": \"<file>src/auth/jwt.py\\n+def validate_token(token): ...\", \"label\": 1},\n",
    "        {\"text\": \"<file>README.md\\n+## Updated documentation\", \"label\": 0},\n",
    "        {\"text\": \"<file>src/core/db.py\\n+def execute_query(sql, params): ...\", \"label\": 1},\n",
    "        {\"text\": \"<file>tests/test_utils.py\\n+def test_helper(): ...\", \"label\": 0},\n",
    "        {\"text\": \"<file>src/crypto/hash.py\\n+def sha256(data): ...\", \"label\": 1},\n",
    "        {\"text\": \"<file>docs/changelog.md\\n+v1.2.0 release notes\", \"label\": 0},\n",
    "    ] * 20  # repeat for a small training set\n",
    "    with open(DATA_PATH, \"w\") as f:\n",
    "        for s in samples:\n",
    "            f.write(json.dumps(s) + \"\\n\")\n",
    "\n",
    "records = load_jsonl(DATA_PATH)\n",
    "print(f\"Loaded {len(records)} records\")\n",
    "print(f\"Label distribution: {sum(r['label'] for r in records)} positive / {len(records)} total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_records, val_records = train_test_split(records, test_size=0.15, random_state=42)\n",
    "print(f\"Train: {len(train_records)}  Val: {len(val_records)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-0008",
   "metadata": {},
   "source": [
    "## 3. Teacher Training — CodeBERT + LoRA\n",
    "\n",
    "We apply LoRA adapters only to the query/value projection matrices, keeping the base CodeBERT weights frozen. This reduces trainable parameters by ~98% while retaining most accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "TEACHER_BASE = \"microsoft/codebert-base\"\n",
    "\n",
    "teacher_tokenizer = AutoTokenizer.from_pretrained(TEACHER_BASE)\n",
    "teacher_base = AutoModelForSequenceClassification.from_pretrained(\n",
    "    TEACHER_BASE, num_labels=1\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"query\", \"value\"],\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "teacher_model = get_peft_model(teacher_base, lora_config)\n",
    "teacher_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0010",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEACHER_EPOCHS = 3\n",
    "TEACHER_LR = 2e-4\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "train_ds = RerankerDataset(train_records, teacher_tokenizer)\n",
    "val_ds = RerankerDataset(val_records, teacher_tokenizer)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "teacher_model.to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(teacher_model.parameters(), lr=TEACHER_LR)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(TEACHER_EPOCHS):\n",
    "    teacher_model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = teacher_model(\n",
    "            input_ids=batch[\"input_ids\"].to(DEVICE),\n",
    "            attention_mask=batch[\"attention_mask\"].to(DEVICE),\n",
    "        )\n",
    "        logits = out.logits.squeeze(-1)\n",
    "        loss = loss_fn(logits, batch[\"labels\"].to(DEVICE))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    teacher_model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            out = teacher_model(\n",
    "                input_ids=batch[\"input_ids\"].to(DEVICE),\n",
    "                attention_mask=batch[\"attention_mask\"].to(DEVICE),\n",
    "            )\n",
    "            logits = out.logits.squeeze(-1)\n",
    "            val_loss += loss_fn(logits, batch[\"labels\"].to(DEVICE)).item()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{TEACHER_EPOCHS} | \"\n",
    "        f\"train_loss={total_loss/len(train_loader):.4f} | \"\n",
    "        f\"val_loss={val_loss/len(val_loader):.4f}\"\n",
    "    )\n",
    "\n",
    "print(\"Teacher training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-0011",
   "metadata": {},
   "source": [
    "## 4. Distillation — CodeT5-small Student\n",
    "\n",
    "We use **soft-label distillation**: the student minimises a weighted sum of\n",
    "- BCE loss against hard labels (ground truth)\n",
    "- KL-divergence loss against teacher soft probabilities\n",
    "\n",
    "Temperature `T=4` softens the teacher distribution so the student learns richer signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0012",
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDENT_BASE = \"Salesforce/codet5-small\"\n",
    "\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(STUDENT_BASE)\n",
    "student_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    STUDENT_BASE, num_labels=1\n",
    ")\n",
    "student_model.to(DEVICE)\n",
    "\n",
    "print(f\"Student params: {sum(p.numel() for p in student_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0013",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillDataset(Dataset):\n",
    "    \"\"\"Pairs (student_encoding, teacher_soft_label, hard_label).\"\"\"\n",
    "\n",
    "    def __init__(self, records, student_tok, teacher_model, teacher_tok, device, max_length=512):\n",
    "        self.records = records\n",
    "        self.student_tok = student_tok\n",
    "        self.max_length = max_length\n",
    "        # Pre-compute teacher soft labels\n",
    "        self.soft_labels = self._compute_soft_labels(teacher_model, teacher_tok, device)\n",
    "\n",
    "    def _compute_soft_labels(self, model, tokenizer, device):\n",
    "        model.eval()\n",
    "        soft = []\n",
    "        texts = [r[\"text\"] for r in self.records]\n",
    "        bs = 16\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(texts), bs):\n",
    "                batch_texts = texts[i : i + bs]\n",
    "                enc = tokenizer(\n",
    "                    batch_texts,\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=self.max_length,\n",
    "                    return_tensors=\"pt\",\n",
    "                ).to(device)\n",
    "                out = model(**enc)\n",
    "                probs = torch.sigmoid(out.logits.squeeze(-1)).cpu().tolist()\n",
    "                if isinstance(probs, float):\n",
    "                    probs = [probs]\n",
    "                soft.extend(probs)\n",
    "        return soft\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rec = self.records[idx]\n",
    "        enc = self.student_tok(\n",
    "            rec[\"text\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
    "            \"hard_label\": torch.tensor(rec[\"label\"], dtype=torch.float),\n",
    "            \"soft_label\": torch.tensor(self.soft_labels[idx], dtype=torch.float),\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"Building distillation dataset (computing teacher soft labels) ...\")\n",
    "distill_ds = DistillDataset(\n",
    "    train_records, student_tokenizer, teacher_model, teacher_tokenizer, DEVICE\n",
    ")\n",
    "distill_loader = DataLoader(distill_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print(f\"Distillation dataset ready: {len(distill_ds)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0014",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTILL_EPOCHS = 4\n",
    "DISTILL_LR = 3e-4\n",
    "ALPHA = 0.5   # weight for hard-label BCE loss\n",
    "TEMPERATURE = 4.0\n",
    "\n",
    "distill_optimizer = torch.optim.AdamW(student_model.parameters(), lr=DISTILL_LR)\n",
    "bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(DISTILL_EPOCHS):\n",
    "    student_model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in distill_loader:\n",
    "        distill_optimizer.zero_grad()\n",
    "\n",
    "        out = student_model(\n",
    "            input_ids=batch[\"input_ids\"].to(DEVICE),\n",
    "            attention_mask=batch[\"attention_mask\"].to(DEVICE),\n",
    "        )\n",
    "        student_logits = out.logits.squeeze(-1)\n",
    "\n",
    "        hard_labels = batch[\"hard_label\"].to(DEVICE)\n",
    "        soft_labels = batch[\"soft_label\"].to(DEVICE)\n",
    "\n",
    "        # Hard-label loss\n",
    "        hard_loss = bce(student_logits, hard_labels)\n",
    "\n",
    "        # Soft-label distillation loss (MSE between sigmoid probabilities)\n",
    "        student_probs = torch.sigmoid(student_logits / TEMPERATURE)\n",
    "        teacher_probs = soft_labels  # already sigmoid-ed\n",
    "        soft_loss = nn.functional.mse_loss(student_probs, teacher_probs)\n",
    "\n",
    "        loss = ALPHA * hard_loss + (1 - ALPHA) * soft_loss\n",
    "        loss.backward()\n",
    "        distill_optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Distill Epoch {epoch+1}/{DISTILL_EPOCHS} | loss={total_loss/len(distill_loader):.4f}\")\n",
    "\n",
    "print(\"Distillation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save student checkpoint (used by ml/models/reranker.py at inference time)\n",
    "student_model.save_pretrained(str(CHECKPOINT_DIR))\n",
    "student_tokenizer.save_pretrained(str(CHECKPOINT_DIR))\n",
    "print(f\"Student checkpoint saved to {CHECKPOINT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-0016",
   "metadata": {},
   "source": [
    "## 5. Benchmark — Teacher vs Student\n",
    "\n",
    "Evaluate both models on the held-out validation set using:\n",
    "- **AUC-ROC** — ranking quality\n",
    "- **Accuracy** at threshold 0.5\n",
    "- **Latency** (ms/sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "\n",
    "def evaluate(model, tokenizer, records, device, label=\"model\", batch_size=16):\n",
    "    model.eval()\n",
    "    all_probs, all_labels = [], []\n",
    "    texts = [r[\"text\"] for r in records]\n",
    "    labels = [r[\"label\"] for r in records]\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i : i + batch_size]\n",
    "            enc = tokenizer(\n",
    "                batch_texts,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                return_tensors=\"pt\",\n",
    "            ).to(device)\n",
    "            out = model(**enc)\n",
    "            probs = torch.sigmoid(out.logits.squeeze(-1)).cpu().tolist()\n",
    "            if isinstance(probs, float):\n",
    "                probs = [probs]\n",
    "            all_probs.extend(probs)\n",
    "    elapsed = time.perf_counter() - t0\n",
    "\n",
    "    auc = roc_auc_score(labels, all_probs)\n",
    "    preds = [1 if p >= 0.5 else 0 for p in all_probs]\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    ms_per_sample = (elapsed / len(texts)) * 1000\n",
    "\n",
    "    print(f\"[{label}] AUC={auc:.4f} | Acc={acc:.4f} | Latency={ms_per_sample:.2f} ms/sample\")\n",
    "    return {\"auc\": auc, \"accuracy\": acc, \"ms_per_sample\": ms_per_sample}\n",
    "\n",
    "\n",
    "print(\"=== Validation Benchmark ===\")\n",
    "teacher_metrics = evaluate(teacher_model, teacher_tokenizer, val_records, DEVICE, label=\"Teacher (CodeBERT+LoRA)\")\n",
    "student_metrics = evaluate(student_model, student_tokenizer, val_records, DEVICE, label=\"Student (CodeT5-small)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0018",
   "metadata": {},
   "outputs": [],
   "source": [
    "speedup = teacher_metrics[\"ms_per_sample\"] / max(student_metrics[\"ms_per_sample\"], 1e-9)\n",
    "auc_gap = teacher_metrics[\"auc\"] - student_metrics[\"auc\"]\n",
    "\n",
    "print(f\"\\nSpeedup: {speedup:.1f}x faster\")\n",
    "print(f\"AUC gap (teacher - student): {auc_gap:.4f}\")\n",
    "\n",
    "if speedup >= 2.0 and auc_gap <= 0.05:\n",
    "    print(\"PASS: Student meets latency and quality targets.\")\n",
    "else:\n",
    "    print(\"WARNING: Targets not met — consider more distillation epochs or temperature tuning.\")"
   ]
  }
 ]
}
