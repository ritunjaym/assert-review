{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title-cell",
   "metadata": {},
   "source": [
    "# Build FAISS Index (Colab)\n",
    "\n",
    "This notebook builds a FAISS dense retrieval index from the assert-review dataset using CodeBERT embeddings.\n",
    "\n",
    "**Steps:**\n",
    "1. Install dependencies\n",
    "2. Mount Google Drive\n",
    "3. Build the FAISS index\n",
    "4. Verify the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install faiss-cpu transformers torch datasets pydantic --quiet\n",
    "print('Dependencies installed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mount-drive-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Clone or pull the repo if not already present\n",
    "REPO_DIR = '/content/assert-review'\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone https://github.com/your-org/assert-review.git {REPO_DIR}\n",
    "else:\n",
    "    !git -C {REPO_DIR} pull\n",
    "\n",
    "# Add repo root to path so ml package is importable\n",
    "if REPO_DIR not in sys.path:\n",
    "    sys.path.insert(0, REPO_DIR)\n",
    "\n",
    "print(f'Repo at: {REPO_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build-index-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build FAISS index from dataset\n",
    "import os\n",
    "\n",
    "# Optional: set W&B key for experiment tracking\n",
    "# os.environ['WANDB_API_KEY'] = 'your-key-here'\n",
    "# os.environ['WANDB_PROJECT'] = 'assert-review'\n",
    "\n",
    "from ml.models.build_index import build_index\n",
    "\n",
    "# Build with optional max_records limit for quick testing\n",
    "# Set max_records=None to index everything\n",
    "index = build_index(\n",
    "    max_records=None,\n",
    "    batch_size=64,\n",
    "    index_path='/content/drive/MyDrive/assert-review/hunk_index.faiss',\n",
    ")\n",
    "\n",
    "print(f'Index built with {index.size} vectors.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify-index-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the index with a test query\n",
    "import numpy as np\n",
    "from ml.models.index import PRIndex\n",
    "from ml.models.embedder import CodeEmbedder\n",
    "\n",
    "# Load the saved index\n",
    "loaded_index = PRIndex(dim=768)\n",
    "loaded_index.load('/content/drive/MyDrive/assert-review/hunk_index.faiss')\n",
    "print(f'Loaded index size: {loaded_index.size} vectors')\n",
    "\n",
    "# Embed a test query and search\n",
    "embedder = CodeEmbedder()\n",
    "query_text = 'def test_assert_raises(): with pytest.raises(ValueError): func()'\n",
    "query_vec = embedder.embed_single(query_text)\n",
    "\n",
    "results = loaded_index.search(query_vec, k=5)\n",
    "print(f'\\nTop-5 results for query: {query_text[:60]}...')\n",
    "print('-' * 60)\n",
    "for i, r in enumerate(results):\n",
    "    print(f'{i+1}. score={r.score:.4f}  file={r.filename}')\n",
    "    print(f'   preview: {r.hunk_preview[:80]}')\n",
    "    print()"
   ]
  }
 ]
}
